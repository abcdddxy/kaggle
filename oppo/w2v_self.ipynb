{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#æ¯æ¬¡å¯ä»¥è¾“å‡ºå¤šä¸ªå˜é‡\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#ä¸­æ–‡å­—ä½“\n",
    "import matplotlib\n",
    "matplotlib.use('qt4agg')\n",
    "#æŒ‡å®šé»˜è®¤å­—ä½“\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "#è§£å†³è´Ÿå·'-'æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vectors(path, topn):  # read top n word vectors, i.e. top is 10000\n",
    "    lines_num, dim = 0, 0\n",
    "    vectors = {}\n",
    "    iw = []\n",
    "    wi = {}\n",
    "    with open(path, encoding='utf-8', errors='ignore') as f:\n",
    "        first_line = True\n",
    "        for line in f:\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                dim = int(line.rstrip().split()[1])\n",
    "                continue\n",
    "            lines_num += 1\n",
    "            tokens = line.rstrip().split(' ')\n",
    "            vectors[tokens[0]] = np.asarray([float(x) for x in tokens[1:]])\n",
    "            iw.append(tokens[0])\n",
    "            if topn != 0 and lines_num >= topn:\n",
    "                break\n",
    "    for i, w in enumerate(iw):\n",
    "        wi[w] = i\n",
    "    return vectors, iw, wi, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./feature/df_feature4_ctr_extra.csv', encoding='utf-8', usecols=['prefix', 'title', 'query_prediction'])\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df.title.apply(lambda x: urllib.parse.unquote(x))\n",
    "df['prefix'] = df.prefix.apply(lambda x: urllib.parse.unquote(x))\n",
    "df['query_prediction'] = df.query_prediction.apply(lambda x: urllib.parse.unquote(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = read_vectors('./data/new/merge_sgns_bigram_char300.txt', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlaw_word(x):\n",
    "    tmp_list = list(jieba.cut(x))\n",
    "    outlaw_word = []\n",
    "    outlaw_letter = []\n",
    "    for word in tmp_list:\n",
    "        if word not in w2v[0]:\n",
    "            outlaw_word.append(word)\n",
    "    return outlaw_word\n",
    "\n",
    "def get_outlaw_letter(x):\n",
    "    tmp_list = list(jieba.cut(x))\n",
    "    outlaw_letter = []\n",
    "    for word in tmp_list:\n",
    "        if word not in w2v[0]:\n",
    "            for letter in word:\n",
    "                if letter not in w2v[0]:\n",
    "                    outlaw_letter.append(letter)\n",
    "    return outlaw_letter\n",
    "\n",
    "def get_dict_outlaw_word(x):\n",
    "    dic = eval(x)\n",
    "    outlaw_word = []\n",
    "    for key in dic.keys():\n",
    "        tmp_list = list(jieba.cut(key))\n",
    "        for word in tmp_list:\n",
    "            if word not in w2v[0]:\n",
    "                outlaw_word.append(word)\n",
    "    return outlaw_word\n",
    "\n",
    "def get_dict_outlaw_letter(x):\n",
    "    dic = eval(x)\n",
    "    outlaw_letter = []\n",
    "    for key in dic.keys():\n",
    "        tmp_list = list(jieba.cut(key))\n",
    "        for word in tmp_list:\n",
    "            if word not in w2v[0]:\n",
    "                for letter in word:\n",
    "                    if letter not in w2v[0]:\n",
    "                        outlaw_letter.append(letter)\n",
    "    return outlaw_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['prefix_outlaw_word'] = df.prefix.apply(get_outlaw_word)\n",
    "df['prefix_outlaw_letter'] = df.prefix.apply(get_outlaw_letter)\n",
    "df['title_outlaw_word'] = df.title.apply(get_outlaw_word)\n",
    "df['title_outlaw_letter'] = df.title.apply(get_outlaw_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['dict_outlaw_word'] = df.query_prediction.apply(get_dict_outlaw_word)\n",
    "df['dict_outlaw_letter'] = df.query_prediction.apply(get_dict_outlaw_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "prefix_outlaw_letter_set = set(reduce(operator.add, df.prefix_outlaw_letter.tolist()))\n",
    "title_outlaw_letter_set = set(reduce(operator.add, df.title_outlaw_letter.tolist()))\n",
    "dict_outlaw_letter_set = set(reduce(operator.add, df.dict_outlaw_letter.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " 'Ù…',\n",
       " 'Ù†',\n",
       " 'Û•',\n",
       " 'ä—ª',\n",
       " 'å‡',\n",
       " 'åšŠ',\n",
       " 'åœ',\n",
       " 'åª£',\n",
       " 'åº',\n",
       " 'æ€£',\n",
       " 'æ±–',\n",
       " 'ç³„',\n",
       " 'è˜¡',\n",
       " 'èœ',\n",
       " 'è²',\n",
       " 'é«ˆ',\n",
       " 'ë…•',\n",
       " 'ë‘',\n",
       " 'ì‚¬',\n",
       " 'ì„¸',\n",
       " 'ì•ˆ',\n",
       " 'ìš”',\n",
       " 'ì²­',\n",
       " 'ì¶˜',\n",
       " 'í•˜',\n",
       " 'í•´'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " 'Ø¦',\n",
       " 'Ø¯',\n",
       " 'Ø²',\n",
       " 'Ù…',\n",
       " 'Ù†',\n",
       " 'Ù‰',\n",
       " 'ÙŠ',\n",
       " 'Û•',\n",
       " 'à¸ˆ',\n",
       " 'à¸”',\n",
       " 'à¸•',\n",
       " 'à¸–',\n",
       " 'à¸™',\n",
       " 'à¸š',\n",
       " 'à¸Ÿ',\n",
       " 'à¸¡',\n",
       " 'à¸£',\n",
       " 'à¸§',\n",
       " 'à¸­',\n",
       " 'à¸±',\n",
       " 'à¸µ',\n",
       " 'à¸¶',\n",
       " 'à¸¹',\n",
       " 'à¹€',\n",
       " 'à¹',\n",
       " 'à¹„',\n",
       " 'à¹ˆ',\n",
       " 'à¹‰',\n",
       " '\\u3000',\n",
       " 'äƒ ',\n",
       " 'ä—ª',\n",
       " 'å¼',\n",
       " 'å‡',\n",
       " 'åšŠ',\n",
       " 'åœ',\n",
       " 'åª£',\n",
       " 'å«¤',\n",
       " 'åº',\n",
       " 'æ€£',\n",
       " 'æœ¤',\n",
       " 'æ®¸',\n",
       " 'æ±–',\n",
       " 'ç¼',\n",
       " 'çŸ†',\n",
       " 'ç¡‚',\n",
       " 'ç³„',\n",
       " 'è……',\n",
       " 'è”©',\n",
       " 'è˜¡',\n",
       " 'è™‹',\n",
       " 'èœ',\n",
       " 'è±¼',\n",
       " 'éŒµ',\n",
       " 'é«ˆ',\n",
       " 'é¯—',\n",
       " 'ê°€',\n",
       " 'ê°',\n",
       " 'ê°™',\n",
       " 'ê±´',\n",
       " 'ê²Œ',\n",
       " 'ê³ ',\n",
       " 'êµ¬',\n",
       " 'ê¸‰',\n",
       " 'ê¸°',\n",
       " 'ê¹Œ',\n",
       " 'ë‚œ',\n",
       " 'ë„¤',\n",
       " 'ë…€',\n",
       " 'ë…•',\n",
       " 'ë…¸',\n",
       " 'ë†',\n",
       " 'ëˆ„',\n",
       " 'ë‹ˆ',\n",
       " 'ë‹¤',\n",
       " 'ëŒ€',\n",
       " 'ë„',\n",
       " 'ë™',\n",
       " 'ë–¨',\n",
       " 'ë˜‘',\n",
       " 'ë¼',\n",
       " 'ë‘',\n",
       " 'ë˜',\n",
       " 'ëŸ½',\n",
       " 'ë ˆ',\n",
       " 'ë¡œ',\n",
       " 'ë¦¬',\n",
       " 'ë¦¼',\n",
       " 'ë§',\n",
       " 'ë§ˆ',\n",
       " 'ë¨¼',\n",
       " 'ëª½',\n",
       " 'ë¬´',\n",
       " 'ë¬¼',\n",
       " 'ë°©',\n",
       " 'ë±€',\n",
       " 'ë²ˆ',\n",
       " 'ë²¨',\n",
       " 'ë³‘',\n",
       " 'ë¶€',\n",
       " 'ë¹„',\n",
       " 'ë¹ˆ',\n",
       " 'ë¹›',\n",
       " 'ë¹ ',\n",
       " 'ë»',\n",
       " 'ë¿',\n",
       " 'ì‚¬',\n",
       " 'ì‚¶',\n",
       " 'ì‚¼',\n",
       " 'ìƒ',\n",
       " 'ìƒˆ',\n",
       " 'ì„¸',\n",
       " 'ì…˜',\n",
       " 'ì†Œ',\n",
       " 'ì†”',\n",
       " 'ìˆ˜',\n",
       " 'ìˆœ',\n",
       " 'ìŠ¤',\n",
       " 'ìŠ¬',\n",
       " 'ì‹œ',\n",
       " 'ì‹',\n",
       " 'ì‹ ',\n",
       " 'ì‹¤',\n",
       " 'ì‹¬',\n",
       " 'ì“°',\n",
       " 'ì”¨',\n",
       " 'ì•„',\n",
       " 'ì•ˆ',\n",
       " 'ì•”',\n",
       " 'ì• ',\n",
       " 'ì•¼',\n",
       " 'ì–´',\n",
       " 'ì—†',\n",
       " 'ì—¬',\n",
       " 'ì˜†',\n",
       " 'ì˜ˆ',\n",
       " 'ì˜¤',\n",
       " 'ìš”',\n",
       " 'ìš°',\n",
       " 'ìš´',\n",
       " 'ì›ƒ',\n",
       " 'ì›Œ',\n",
       " 'ì›',\n",
       " 'ìŒ',\n",
       " 'ì‘',\n",
       " 'ì¸',\n",
       " 'ìˆ',\n",
       " 'ì',\n",
       " 'ì”',\n",
       " 'ì ',\n",
       " 'ì¥',\n",
       " 'ì¬',\n",
       " 'ì¡°',\n",
       " 'ì¡±',\n",
       " 'ì£¼',\n",
       " 'ì¤„',\n",
       " 'ì§„',\n",
       " 'ì§ˆ',\n",
       " 'ì§‘',\n",
       " 'ì§œ',\n",
       " 'ì²­',\n",
       " 'ì¶˜',\n",
       " 'ì¹˜',\n",
       " 'ì¼€',\n",
       " 'ì½˜',\n",
       " 'í……',\n",
       " 'íˆ¬',\n",
       " 'íŠ¸',\n",
       " 'í‹€',\n",
       " 'íŒ”',\n",
       " 'í¼',\n",
       " 'í•˜',\n",
       " 'í•´',\n",
       " 'í–¥',\n",
       " 'í™”',\n",
       " 'ï§˜'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " '\\x91',\n",
       " '\\x98',\n",
       " 'Ø¨',\n",
       " 'Ø¯',\n",
       " 'Ø²',\n",
       " 'Ø³',\n",
       " 'Ø´',\n",
       " 'Ù‚',\n",
       " 'Ùƒ',\n",
       " 'Ù„',\n",
       " 'Ù…',\n",
       " 'Ù†',\n",
       " 'Ù‰',\n",
       " 'ÙŠ',\n",
       " 'Ú†',\n",
       " 'Û‡',\n",
       " 'Û•',\n",
       " 'ã–­',\n",
       " 'ã—Š',\n",
       " 'ãš',\n",
       " 'ã ­',\n",
       " 'ã¡Œ',\n",
       " 'ã¬µ',\n",
       " 'ãµ˜',\n",
       " 'ä‚³',\n",
       " 'ä“',\n",
       " 'ä—ª',\n",
       " 'ä¨»',\n",
       " 'ä²œ',\n",
       " 'åƒº',\n",
       " 'å†¸',\n",
       " 'å‹¥',\n",
       " 'å‡',\n",
       " 'å‘',\n",
       " 'åšŠ',\n",
       " 'åœ',\n",
       " 'å¥¾',\n",
       " 'å¦¦',\n",
       " 'å§€',\n",
       " 'å©›',\n",
       " 'åªˆ',\n",
       " 'åª£',\n",
       " 'å«',\n",
       " 'å«¤',\n",
       " 'å«´',\n",
       " 'å³“',\n",
       " 'åº',\n",
       " 'å¿ˆ',\n",
       " 'æ€£',\n",
       " 'æƒ—',\n",
       " 'æ˜®',\n",
       " 'æœ¤',\n",
       " 'æ‹',\n",
       " 'æŸ›',\n",
       " 'æ¡‹',\n",
       " 'æ¢š',\n",
       " 'æ¨°',\n",
       " 'æ®…',\n",
       " 'æ±ƒ',\n",
       " 'æ±–',\n",
       " 'æ¸‚',\n",
       " 'çª',\n",
       " 'ç‚',\n",
       " 'ç‡œ',\n",
       " 'çŠ¾',\n",
       " 'ç»',\n",
       " 'ç¾',\n",
       " 'ç‘µ',\n",
       " 'ç’¾',\n",
       " 'ç“ƒ',\n",
       " 'ç¡£',\n",
       " 'ç¨¥',\n",
       " 'ç­£',\n",
       " 'ç®‰',\n",
       " 'ç³„',\n",
       " 'ç½³',\n",
       " 'è—Œ',\n",
       " 'è˜¡',\n",
       " 'è›¦',\n",
       " 'èœ…',\n",
       " 'èœ',\n",
       " 'èŸ',\n",
       " 'è©º',\n",
       " 'è±¼',\n",
       " 'éƒ£',\n",
       " 'é«ˆ',\n",
       " 'é²',\n",
       " 'é´›',\n",
       " 'é´¦',\n",
       " 'é½«',\n",
       " 'êµ­',\n",
       " 'ë…•',\n",
       " 'ë‘',\n",
       " 'ì‚¬',\n",
       " 'ì„¸',\n",
       " 'ì•ˆ',\n",
       " 'ì–´',\n",
       " 'ìš”',\n",
       " 'ì „',\n",
       " 'ì¤‘',\n",
       " 'í•˜',\n",
       " 'í•´',\n",
       " 'ğŸ ',\n",
       " 'ğŸ”‘'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_outlaw_letter_set\n",
    "title_outlaw_letter_set\n",
    "dict_outlaw_letter_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>query_prediction</th>\n",
       "      <th>title</th>\n",
       "      <th>prefix_outlaw_word</th>\n",
       "      <th>prefix_outlaw_letter</th>\n",
       "      <th>title_outlaw_word</th>\n",
       "      <th>title_outlaw_letter</th>\n",
       "      <th>dict_outlaw_word</th>\n",
       "      <th>dict_outlaw_letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>å°å“</td>\n",
       "      <td>{'å°å“å¤§å…¨': '0.198', 'å°å“æç¬‘å¤§å…¨': '0.066', 'å°å“æ¼”å‘˜': '...</td>\n",
       "      <td>å°å“</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1368</td>\n",
       "      <td>{'13685367892': '0.124', '1368å¹´': '0.086', '13...</td>\n",
       "      <td>HCGå¤§äº1368,æ­£å¸¸å—</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[13685367892, å°±å¤Ÿ, 13688cc, 13688478100, 13688c...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1368</td>\n",
       "      <td>{'13685367892': '0.124', '1368å¹´': '0.086', '13...</td>\n",
       "      <td>1368å¹´</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[13685367892, å°±å¤Ÿ, 13688cc, 13688478100, 13688c...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>é“¶è€³</td>\n",
       "      <td>{'é“¶è€³çº¢æ£æ±¤': '0.114', 'é“¶è€³æ±¤çš„åšæ³•': '0.059', 'é“¶è€³çš„åŠŸæ•ˆ':...</td>\n",
       "      <td>é“¶è€³çº¢æ£æ±¤çš„åšæ³•</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>æœˆç»é‡å°‘</td>\n",
       "      <td>{'æœˆç»é‡å°‘æ˜¯ä»€ä¹ˆåŸå› ': '0.569', 'æœˆç»é‡å°‘æ€ä¹ˆåŠ': '0.040', 'æœˆç»...</td>\n",
       "      <td>æœˆç»é‡å°‘æ€ä¹ˆè°ƒç†</td>\n",
       "      <td>[é‡å°‘]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[é‡å°‘]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prefix                                   query_prediction          title  \\\n",
       "0     å°å“  {'å°å“å¤§å…¨': '0.198', 'å°å“æç¬‘å¤§å…¨': '0.066', 'å°å“æ¼”å‘˜': '...             å°å“   \n",
       "1   1368  {'13685367892': '0.124', '1368å¹´': '0.086', '13...  HCGå¤§äº1368,æ­£å¸¸å—   \n",
       "2   1368  {'13685367892': '0.124', '1368å¹´': '0.086', '13...          1368å¹´   \n",
       "3     é“¶è€³  {'é“¶è€³çº¢æ£æ±¤': '0.114', 'é“¶è€³æ±¤çš„åšæ³•': '0.059', 'é“¶è€³çš„åŠŸæ•ˆ':...       é“¶è€³çº¢æ£æ±¤çš„åšæ³•   \n",
       "4   æœˆç»é‡å°‘  {'æœˆç»é‡å°‘æ˜¯ä»€ä¹ˆåŸå› ': '0.569', 'æœˆç»é‡å°‘æ€ä¹ˆåŠ': '0.040', 'æœˆç»...       æœˆç»é‡å°‘æ€ä¹ˆè°ƒç†   \n",
       "\n",
       "  prefix_outlaw_word prefix_outlaw_letter title_outlaw_word  \\\n",
       "0                 []                   []                []   \n",
       "1                 []                   []                []   \n",
       "2                 []                   []                []   \n",
       "3                 []                   []                []   \n",
       "4               [é‡å°‘]                   []              [é‡å°‘]   \n",
       "\n",
       "  title_outlaw_letter                                   dict_outlaw_word  \\\n",
       "0                  []                                                 []   \n",
       "1                  []  [13685367892, å°±å¤Ÿ, 13688cc, 13688478100, 13688c...   \n",
       "2                  []  [13685367892, å°±å¤Ÿ, 13688cc, 13688478100, 13688c...   \n",
       "3                  []                                                 []   \n",
       "4                  []           [é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘, é‡å°‘]   \n",
       "\n",
       "  dict_outlaw_letter  \n",
       "0                 []  \n",
       "1                 []  \n",
       "2                 []  \n",
       "3                 []  \n",
       "4                 []  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = KeyedVectors.load_word2vec_format('C:/Users/ZERO/KaggleWork/kaggle/w2v/Tencent_AILab_ChineseEmbedding.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v = read_vectors('C:/Users/ZERO/KaggleWork/kaggle/w2v/merge_sgns_bigram_char300.txt', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dictionary(path):\n",
    "    vectors = []\n",
    "    with open(path, encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            word = line.split('\\t')[0]\n",
    "            if (word != 'UNK') & (word != 'PAD'):\n",
    "                vectors.append(word)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = read_dictionary('./model/rnn/rnn/output/dictionary/words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d65820ec0a3438596d0ba624645e276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./model/rnn/rnn/output/dictionary/dict_char300', 'w', encoding='utf-8') as f:\n",
    "    for i in tqdm_notebook(dictionary):\n",
    "        if i in w2v[0]:\n",
    "            vector = '\\t'.join(np.array(w2v[0][i]).astype(str))\n",
    "            _ = f.write('%s\\t%s\\n' % (i, vector))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
